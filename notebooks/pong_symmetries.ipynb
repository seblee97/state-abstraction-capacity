{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9782cec6-a93b-4589-8c38-92640ff63f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "# import gym\n",
    "import sys\n",
    "sys.modules['gym'] = gym\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b3cdc3-3914-4d6a-915c-a6885325bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c66852e2-5726-4377-88ed-2a68920798ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ALE version:\", ale_py.__version__)\n",
    "# gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd3d190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongSymmetryAnalyzer:\n",
    "    \"\"\"\n",
    "    A class for analyzing symmetries in Pong environments using RAM observations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the Pong environment with RAM observations.\n",
    "        \n",
    "        Args:\n",
    "            render_mode: Rendering mode for the environment (None, \"human\", etc.)\n",
    "        \"\"\"\n",
    "        # Register ALE environments\n",
    "#         gym.register_envs(ale_py)\n",
    "        \n",
    "#         # Create environment with RAM observations\n",
    "#         self.env = gym.make(\n",
    "#             \"ALE/Pong-v5\",\n",
    "#             obs_type=\"ram\",\n",
    "#             render_mode=render_mode,\n",
    "#         )\n",
    "        \n",
    "        # RAM indices for extracting game state\n",
    "        self.PONG_RAM_INDEX = {\n",
    "            \"ball_x\": 49,\n",
    "            \"ball_y\": 54,\n",
    "            \"enemy_y\": 50,\n",
    "            \"player_y\": 51,\n",
    "        }\n",
    "        \n",
    "        # Game boundaries\n",
    "        self.BALL_X_MIN = 50\n",
    "        self.BALL_X_MAX = 208\n",
    "        self.BALL_Y_MIN = 44\n",
    "        self.BALL_Y_MAX = 207\n",
    "        self.PLAYER_Y_MIN = 38\n",
    "        self.PLAYER_Y_MAX = 203\n",
    "        self.ENEMY_Y_MIN = 0\n",
    "        self.ENEMY_Y_MAX = 208\n",
    "        \n",
    "        self.BALL_X_MID = (self.BALL_X_MAX - self.BALL_X_MIN) / 2\n",
    "        self.BALL_Y_MID = (self.BALL_Y_MAX - self.BALL_Y_MIN) / 2\n",
    "\n",
    "        self.PLAYER_Y_MID = (self.PLAYER_Y_MAX - self.PLAYER_Y_MIN) / 2\n",
    "        self.ENEMY_Y_MID = (self.ENEMY_Y_MAX - self.ENEMY_Y_MIN) / 2\n",
    "        \n",
    "        # Store sampled states\n",
    "        self.sampled_states: List[Dict[str, Any]] = []\n",
    "        \n",
    "    def ram_to_logic_state(\n",
    "        self, \n",
    "        ram: np.ndarray, \n",
    "        prev_state: Optional[Dict[str, Any]] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Convert RAM observation to logical game state.\n",
    "        \n",
    "        Args:\n",
    "            ram: 128-byte RAM vector from the environment\n",
    "            prev_state: Previous logical state for velocity calculation\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing ball position, velocity, and paddle positions\n",
    "        \"\"\"\n",
    "        # Extract raw positions from RAM\n",
    "        ball_x_raw = int(ram[self.PONG_RAM_INDEX[\"ball_x\"]])\n",
    "        ball_y_raw = int(ram[self.PONG_RAM_INDEX[\"ball_y\"]])\n",
    "        enemy_y_raw = int(ram[self.PONG_RAM_INDEX[\"enemy_y\"]])\n",
    "        player_y_raw = int(ram[self.PONG_RAM_INDEX[\"player_y\"]])\n",
    "        \n",
    "        # Check if ball exists (OCAtari condition)\n",
    "        ball_exists = (ball_y_raw != 0) and (ball_x_raw > 49)\n",
    "        \n",
    "        # Set ball position (None if ball doesn't exist)\n",
    "        ball_x = ball_x_raw if ball_exists else None\n",
    "        ball_y = ball_y_raw if ball_exists else None\n",
    "        \n",
    "        # Paddle positions\n",
    "        player_y = player_y_raw\n",
    "        enemy_y = enemy_y_raw\n",
    "        \n",
    "        # Calculate velocity via finite differences\n",
    "        if (prev_state is not None and \n",
    "            prev_state.get(\"ball_x\") is not None and \n",
    "            ball_x is not None):\n",
    "            ball_dx = ball_x - prev_state[\"ball_x\"]\n",
    "            ball_dy = ball_y - prev_state[\"ball_y\"]\n",
    "        else:\n",
    "            ball_dx = 0\n",
    "            ball_dy = 0\n",
    "            \n",
    "        return {\n",
    "            \"ball_x\": ball_x,\n",
    "            \"ball_y\": ball_y,\n",
    "            \"ball_dx\": ball_dx,\n",
    "            \"ball_dy\": ball_dy,\n",
    "            \"player_y\": player_y,\n",
    "            \"enemy_y\": enemy_y,\n",
    "        }\n",
    "    \n",
    "    def sample_states(\n",
    "        self, \n",
    "        num_episodes: int = 5, \n",
    "        max_steps_per_episode: int = 1000,\n",
    "        model: Optional[Any] = None,\n",
    "        max_states: Optional[int] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Sample states from the environment using either a model or random policy.\n",
    "        \n",
    "        Args:\n",
    "            num_episodes: Number of episodes to run\n",
    "            max_steps_per_episode: Maximum steps per episode\n",
    "            model: Optional model with select_action method. If None, uses random policy\n",
    "            max_states: Maximum number of states to collect. If None, no limit\n",
    "            \n",
    "        Returns:\n",
    "            List of logical game states\n",
    "        \"\"\"\n",
    "        self.sampled_states = []\n",
    "        \n",
    "        for ep in range(num_episodes):\n",
    "            ram, info = self.env.reset()\n",
    "            prev_state = None\n",
    "            \n",
    "            for t in range(max_steps_per_episode):\n",
    "                # Convert RAM to logical state\n",
    "                state = self.ram_to_logic_state(ram, prev_state=prev_state)\n",
    "                self.sampled_states.append(state)\n",
    "                prev_state = state\n",
    "                \n",
    "                # Check if we've reached the maximum number of states\n",
    "                if max_states is not None and len(self.sampled_states) >= max_states:\n",
    "                    return self.sampled_states\n",
    "                \n",
    "                # Select action using model or random policy\n",
    "                if model is not None:\n",
    "                    # Assume model has a select_action method\n",
    "                    if hasattr(model, 'select_action'):\n",
    "                        action = model.select_action(ram)\n",
    "                    elif hasattr(model, 'predict'):\n",
    "                        action = model.predict(ram)\n",
    "                    else:\n",
    "                        # Try calling the model directly\n",
    "                        action = model(ram)\n",
    "                else:\n",
    "                    # Random policy\n",
    "                    action = self.env.action_space.sample()\n",
    "                \n",
    "                # Take step in environment\n",
    "                ram, reward, terminated, truncated, info = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "        return self.sampled_states\n",
    "    \n",
    "    def naive_symmetry(self, state_1: Dict[str, Any], state_2: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        Check if two states are symmetric under naive symmetry assumption.\n",
    "        Ignores scores and opponent paddle position, bins coordinates.\n",
    "        \n",
    "        Args:\n",
    "            state_1: First game state\n",
    "            state_2: Second game state\n",
    "            \n",
    "        Returns:\n",
    "            True if states are considered symmetric, False otherwise\n",
    "        \"\"\"\n",
    "        # Check if ball x positions and x velocities match\n",
    "        ballx = state_1[\"ball_x\"] == state_2[\"ball_x\"]\n",
    "        balldx = state_1[\"ball_dx\"] == state_2[\"ball_dx\"]\n",
    "        \n",
    "        if not ballx or not balldx:\n",
    "            return False\n",
    "            \n",
    "        bally = state_1[\"ball_y\"] == state_2[\"ball_y\"]\n",
    "        balldy = state_1[\"ball_dy\"] == state_2[\"ball_dy\"]\n",
    "        playery = state_1[\"player_y\"] == state_2[\"player_y\"]\n",
    "        \n",
    "        # Case 1: Completely equal\n",
    "        if bally and balldy and playery:\n",
    "            return True\n",
    "        \n",
    "        # Case 2: Ball off screen, paddle positions symmetric\n",
    "        if state_1[\"ball_y\"] is None and state_2[\"ball_y\"] is None:\n",
    "            if (abs(state_1[\"player_y\"] - self.BALL_Y_MID) == \n",
    "                abs(state_2[\"player_y\"] - self.BALL_Y_MID)):\n",
    "                return True\n",
    "        \n",
    "        # Case 3: Symmetric reflection about y-axis\n",
    "        if (state_1[\"ball_y\"] is not None and state_2[\"ball_y\"] is not None):\n",
    "            ball_y_symmetric = (abs(state_1[\"ball_y\"] - self.BALL_Y_MID) == \n",
    "                              abs(state_2[\"ball_y\"] - self.BALL_Y_MID))\n",
    "            player_y_symmetric = (abs(state_1[\"player_y\"] - self.PLAYER_Y_MID) == \n",
    "                                abs(state_2[\"player_y\"] - self.PLAYER_Y_MID))\n",
    "            ball_dy_opposite = state_1[\"ball_dy\"] == -state_2[\"ball_dy\"]\n",
    "            \n",
    "            if ball_y_symmetric and player_y_symmetric and ball_dy_opposite:\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    def generate_similarity_matrix(\n",
    "        self, \n",
    "        states: Optional[List[Dict[str, Any]]] = None,\n",
    "        symmetry_function: Optional[Callable] = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate a similarity matrix for the given states using a symmetry function.\n",
    "        \n",
    "        Args:\n",
    "            states: List of states to compare. If None, uses self.sampled_states\n",
    "            symmetry_function: Function to check symmetry between two states.\n",
    "                             If None, uses self.naive_symmetry\n",
    "                             \n",
    "        Returns:\n",
    "            Binary similarity matrix where entry (i,j) is 1 if states i and j are symmetric\n",
    "        \"\"\"\n",
    "        if states is None:\n",
    "            states = self.sampled_states\n",
    "            \n",
    "        if symmetry_function is None:\n",
    "            symmetry_function = self.naive_symmetry\n",
    "            \n",
    "        if len(states) == 0:\n",
    "            raise ValueError(\"No states provided for similarity matrix generation\")\n",
    "            \n",
    "        matrix = np.zeros((len(states), len(states)), dtype=int)\n",
    "        \n",
    "        for i, state_i in enumerate(states):\n",
    "            for j, state_j in enumerate(states):\n",
    "                matrix[i][j] = int(symmetry_function(state_i, state_j))\n",
    "                \n",
    "        return matrix\n",
    "    \n",
    "    def get_similarity_stats(self, similarity_matrix: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute statistics about the similarity matrix.\n",
    "        \n",
    "        Args:\n",
    "            similarity_matrix: Binary similarity matrix\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with statistics about symmetries\n",
    "        \"\"\"\n",
    "        n = similarity_matrix.shape[0]\n",
    "        total_pairs = n * (n - 1) // 2  # Exclude diagonal\n",
    "        \n",
    "        # Count symmetric pairs (excluding diagonal)\n",
    "        symmetric_pairs = (np.sum(similarity_matrix) - n) // 2\n",
    "        \n",
    "        return {\n",
    "            \"total_states\": n,\n",
    "            \"total_pairs\": total_pairs,\n",
    "            \"symmetric_pairs\": symmetric_pairs,\n",
    "            \"symmetry_ratio\": symmetric_pairs / total_pairs if total_pairs > 0 else 0.0,\n",
    "            \"diagonal_sum\": np.sum(np.diag(similarity_matrix)),\n",
    "        }\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the environment.\"\"\"\n",
    "        # self.env.close()\n",
    "        pass\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize analyzer\n",
    "#     analyzer = PongSymmetryAnalyzer()\n",
    "    \n",
    "#     # Sample states using random policy\n",
    "#     states = analyzer.sample_states(\n",
    "#         num_episodes=3, \n",
    "#         max_steps_per_episode=500,\n",
    "#         max_states=100\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Sampled {len(states)} states\")\n",
    "    \n",
    "#     # Generate similarity matrix\n",
    "#     similarity_matrix = analyzer.generate_similarity_matrix()\n",
    "    \n",
    "#     # Get statistics\n",
    "#     stats = analyzer.get_similarity_stats(similarity_matrix)\n",
    "#     print(\"Similarity Statistics:\")\n",
    "#     for key, value in stats.items():\n",
    "#         print(f\"  {key}: {value}\")\n",
    "    \n",
    "#     # Close environment\n",
    "#     analyzer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13c3bfea-6f37-47aa-beeb-7efc58d9b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_symmetry(state_1, state_2):\n",
    "    \"\"\"\n",
    "    In this naive treatment, I ignore: scores, opponent paddle position.\n",
    "    I bin the x, y coordinates of the ball.\n",
    "    I bin the y coordinate of the player paddle.\n",
    "    Function returns True if: \n",
    "        - coarse x is equal in both states\n",
    "        - dx is equal in both states\n",
    "        - AND ball y and paddle y are equal OR equal on reflection in y=0 line\n",
    "    \"\"\"\n",
    "    ballx = state_1[\"ball_x\"] == state_2[\"ball_x\"]\n",
    "    balldx = state_1[\"ball_dx\"] == state_2[\"ball_dx\"]\n",
    "\n",
    "    if not ballx or not balldx:\n",
    "        return False\n",
    "        \n",
    "    bally = state_1[\"ball_y\"] == state_2[\"ball_y\"]\n",
    "    balldy = state_1[\"ball_dy\"] == state_2[\"ball_dy\"] \n",
    "\n",
    "    playery = state_1[\"player_y\"] == state_2[\"player_y\"] \n",
    "\n",
    "    # case 1: completely equal\n",
    "    if bally:\n",
    "        if balldy:\n",
    "            if playery:\n",
    "                return True\n",
    "\n",
    "    # case 2: ball off screen. paddle flipped\n",
    "    if state_1[\"ball_y\"] is None:\n",
    "        if abs(state_1[\"player_y\"] - BALL_Y_MID) == abs(state_2[\"player_y\"] - BALL_Y_MID):\n",
    "            return True\n",
    "        \n",
    "    # case 2: flipped\n",
    "    if state_1[\"ball_y\"] is not None:\n",
    "        if abs(state_1[\"ball_y\"] - BALL_Y_MID) == abs(state_2[\"ball_y\"] - BALL_Y_MID):\n",
    "            if abs(state_1[\"player_y\"] - BALL_Y_MID) == abs(state_2[\"player_y\"] - BALL_Y_MID):\n",
    "                if state_1[\"ball_dy\"] == -state_2[\"ball_dy\"]:\n",
    "                    return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db237caa-9b39-4f83-b3ac-df2d45b9ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix(states):\n",
    "    matrix = np.zeros((len(states), len(states)))\n",
    "    for i, state_i in enumerate(states):\n",
    "        for j, state_j in enumerate(states):\n",
    "            matrix[i][j] = naive_symmetry(state_i, state_j)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab0d87f7-4c15-415d-b568-c48d7213f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PONG_RAM_INDEX = {\n",
    "    \"ball_x\":   49,\n",
    "    \"ball_y\":   54,\n",
    "    \"enemy_y\":  50,\n",
    "    \"player_y\": 51,\n",
    "}\n",
    "\n",
    "BALL_X_MIN = 50\n",
    "BALL_X_MAX = 208\n",
    "BALL_Y_MIN = 44\n",
    "BALL_Y_MAX = 207\n",
    "PLAYER_Y_MIN = 38\n",
    "PLAYER_Y_MAX = 203\n",
    "ENEMY_Y_MIN = 0\n",
    "ENEMY_Y_MAX = 208\n",
    "\n",
    "BALL_X_MID = (BALL_X_MAX - BALL_X_MIN) / 2\n",
    "BALL_Y_MID = (BALL_Y_MAX - BALL_Y_MIN) / 2\n",
    "\n",
    "PLAYER_Y_MID = (PLAYER_Y_MAX - PLAYER_Y_MIN) / 2\n",
    "ENEMY_Y_MID = (ENEMY_Y_MAX - ENEMY_Y_MIN) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09745f46-0ffb-4ef3-9ebd-46cc9b775093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ram_to_logic_state(\n",
    "    ram: np.ndarray,\n",
    "    prev_state: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Minimal logic-level state for ALE Pong from a 128-byte RAM vector.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"ball_x\":   int or None,\n",
    "            \"ball_y\":   int or None,\n",
    "            \"ball_dx\":  int,\n",
    "            \"ball_dy\":  int,\n",
    "            \"player_y\": int or None,\n",
    "            \"enemy_y\":  int or None,\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Raw positions from RAM (as in OCAtari)\n",
    "    ball_x_raw   = int(ram[PONG_RAM_INDEX[\"ball_x\"]])\n",
    "    ball_y_raw   = int(ram[PONG_RAM_INDEX[\"ball_y\"]])\n",
    "    enemy_y_raw  = int(ram[PONG_RAM_INDEX[\"enemy_y\"]])\n",
    "    player_y_raw = int(ram[PONG_RAM_INDEX[\"player_y\"]])\n",
    "\n",
    "    # OCAtari condition for “ball exists”\n",
    "    ball_exists = (ball_y_raw != 0) and (ball_x_raw > 49)\n",
    "\n",
    "    # If you want to treat \"no ball\" explicitly:\n",
    "    ball_x = ball_x_raw if ball_exists else None\n",
    "    ball_y = ball_y_raw if ball_exists else None\n",
    "\n",
    "    # Paddles basically always exist when game is running;\n",
    "    # if you want to mirror OCAtari, you could add checks similar to ram[50] / ram[51] ranges.\n",
    "    player_y = player_y_raw\n",
    "    enemy_y  = enemy_y_raw\n",
    "\n",
    "    # Velocity via finite differences\n",
    "    if prev_state is not None and prev_state.get(\"ball_x\") is not None and ball_x is not None:\n",
    "        ball_dx = ball_x - prev_state[\"ball_x\"]\n",
    "        ball_dy = ball_y - prev_state[\"ball_y\"]\n",
    "    else:\n",
    "        ball_dx = 0\n",
    "        ball_dy = 0\n",
    "\n",
    "    return {\n",
    "        \"ball_x\":   ball_x,\n",
    "        \"ball_y\":   ball_y,\n",
    "        \"ball_dx\":  ball_dx,\n",
    "        \"ball_dy\":  ball_dy,\n",
    "        \"player_y\": player_y,\n",
    "        \"enemy_y\":  enemy_y,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ea17a6-06f2-40ee-b8d4-bfb49677a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    ball_x_vals = []\n",
    "    ball_y_vals = []\n",
    "    \n",
    "    player_y_vals = []\n",
    "    enemy_y_vals = []\n",
    "    \n",
    "    num_episodes = 5000          # tweak as you like\n",
    "    max_steps_per_ep = 10000    # to cap runtime\n",
    "    \n",
    "    \n",
    "    def update_stats_from_state(state):\n",
    "        if state[\"ball_x\"] is not None and state[\"ball_y\"] is not None:\n",
    "            ball_x_vals.append(state[\"ball_x\"])\n",
    "            ball_y_vals.append(state[\"ball_y\"])\n",
    "        player_y_vals.append(state[\"player_y\"])\n",
    "        enemy_y_vals.append(state[\"enemy_y\"])\n",
    "    \n",
    "    \n",
    "    # --- Run random rollouts and collect stats ---\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        ram, info = env.reset()\n",
    "        prev_state = None\n",
    "    \n",
    "        for t in range(max_steps_per_ep):\n",
    "            state = ram_to_logic_state(ram, prev_state=prev_state)\n",
    "            update_stats_from_state(state)\n",
    "            prev_state = state\n",
    "    \n",
    "            action = env.action_space.sample()\n",
    "            step_out = env.step(action)\n",
    "    \n",
    "            ram, reward, terminated, truncated, info = step_out\n",
    "            done = terminated or truncated\n",
    "            # ram, reward, done, info = step_out\n",
    "    \n",
    "            if done:\n",
    "                break\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    # --- Compute and print stats ---\n",
    "    \n",
    "    def summarize(name, values):\n",
    "        if len(values) == 0:\n",
    "            print(f\"{name}: no data collected\")\n",
    "            return\n",
    "        v = np.array(values)\n",
    "        print(\n",
    "            f\"{name}: min={v.min()}, max={v.max()}, mean={v.mean():.2f}, \"\n",
    "            f\"unique={len(np.unique(v))}\"\n",
    "        )\n",
    "    summarize(\"ball_x\", ball_x_vals)\n",
    "    summarize(\"ball_y\", ball_y_vals)\n",
    "    summarize(\"player_y\", player_y_vals)\n",
    "    summarize(\"enemy_y\", enemy_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc3a99",
   "metadata": {},
   "source": [
    "# RSA Analysis with Hugging Face Models\n",
    "\n",
    "This section downloads trained models from Hugging Face and performs Representational Similarity Analysis (RSA) on the activations to compare with our behavioral similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a20b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Hugging Face models\n",
    "# !pip install stable-baselines3[extra] huggingface_sb3 torch torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "# import gym as gym_old\n",
    "from huggingface_sb3 import load_from_hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3edac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelActivationExtractor:\n",
    "    \"\"\"\n",
    "    Extract activations from different layers of trained RL models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, model_type='ppo'):\n",
    "        self.model = model\n",
    "        self.model_type = model_type.lower()\n",
    "        self.activations = {}\n",
    "        self.hooks = []\n",
    "        \n",
    "    def register_hooks(self, layer_names=None):\n",
    "        \"\"\"Register forward hooks to capture activations.\"\"\"\n",
    "        def hook_fn(name):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, torch.Tensor):\n",
    "                    self.activations[name] = output.detach().cpu().numpy()\n",
    "                elif isinstance(output, (list, tuple)):\n",
    "                    # Handle cases where output is a tuple/list\n",
    "                    self.activations[name] = output[0].detach().cpu().numpy()\n",
    "            return hook\n",
    "            \n",
    "        # Get the policy network\n",
    "        if hasattr(self.model, 'policy'):\n",
    "            policy_net = self.model.policy\n",
    "        else:\n",
    "            policy_net = self.model\n",
    "            \n",
    "        # Register hooks for different model architectures\n",
    "        if hasattr(policy_net, 'features_extractor'):\n",
    "            # CNN-based models\n",
    "            cnn = policy_net.features_extractor.cnn\n",
    "            for i, layer in enumerate(cnn):\n",
    "                if isinstance(layer, (nn.Conv2d, nn.Linear, nn.ReLU)):\n",
    "                    name = f'cnn_layer_{i}_{layer.__class__.__name__}'\n",
    "                    if layer_names is None or name in layer_names:\n",
    "                        hook = layer.register_forward_hook(hook_fn(name))\n",
    "                        self.hooks.append(hook)\n",
    "                        \n",
    "        # Value and policy heads\n",
    "        if hasattr(policy_net, 'value_net'):\n",
    "            for i, layer in enumerate(policy_net.value_net):\n",
    "                if isinstance(layer, (nn.Linear, nn.ReLU)):\n",
    "                    name = f'value_net_{i}_{layer.__class__.__name__}'\n",
    "                    if layer_names is None or name in layer_names:\n",
    "                        hook = layer.register_forward_hook(hook_fn(name))\n",
    "                        self.hooks.append(hook)\n",
    "                        \n",
    "        if hasattr(policy_net, 'action_net'):\n",
    "            for i, layer in enumerate(policy_net.action_net):\n",
    "                if isinstance(layer, (nn.Linear, nn.ReLU)):\n",
    "                    name = f'action_net_{i}_{layer.__class__.__name__}'\n",
    "                    if layer_names is None or name in layer_names:\n",
    "                        hook = layer.register_forward_hook(hook_fn(name))\n",
    "                        self.hooks.append(hook)\n",
    "    \n",
    "    def extract_activations(self, states):\n",
    "        \"\"\"Extract activations for a batch of states.\"\"\"\n",
    "        self.activations.clear()\n",
    "        \n",
    "        # Convert states to tensor\n",
    "        if isinstance(states, np.ndarray):\n",
    "            states_tensor = torch.FloatTensor(states)\n",
    "        else:\n",
    "            states_tensor = torch.FloatTensor(np.array(states))\n",
    "            \n",
    "        # Ensure correct shape (batch_size, channels, height, width)\n",
    "        if len(states_tensor.shape) == 3:\n",
    "            states_tensor = states_tensor.unsqueeze(0)\n",
    "        if states_tensor.shape[-1] == 3:  # If channels last\n",
    "            states_tensor = states_tensor.permute(0, 3, 1, 2)\n",
    "            \n",
    "        # Normalize to [0, 1] if needed\n",
    "        if states_tensor.max() > 1.0:\n",
    "            states_tensor = states_tensor / 255.0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if self.model_type in ['ppo', 'a2c']:\n",
    "                # For policy gradient methods\n",
    "                self.model.policy(states_tensor)\n",
    "            elif self.model_type == 'dqn':\n",
    "                # For Q-learning methods\n",
    "                self.model.q_net(states_tensor)\n",
    "                \n",
    "        return dict(self.activations)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Remove all registered hooks.\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f7e94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "\n",
    "def download_models(env_name: str = \"PongNoFrameskip-v4\"):\n",
    "    \"\"\"Download pre-trained models from Hugging Face.\"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # pre-create environment\n",
    "    # env = gym.make(env_name, render_mode=\"human\")\n",
    "    # env = ChannelFirstWrapper(env)\n",
    "    env = make_atari_env(env_name, n_envs=1, env_kwargs={\"render_mode\": \"human\"})\n",
    "    env = VecFrameStack(env, n_stack=4)\n",
    "    env = VecTransposeImage(env)\n",
    "\n",
    "    # 4. Load with CUSTOM_OBJECTS override\n",
    "    # This replaces the metadata from the file with the spaces from your current env\n",
    "    custom_objects = {\n",
    "        \"observation_space\": env.observation_space,\n",
    "        \"action_space\": env.action_space\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # PPO model\n",
    "        print(\"Downloading PPO model...\")\n",
    "        ppo_path = load_from_hub(\n",
    "            repo_id=f\"sb3/ppo-{env_name}\",\n",
    "            filename=f\"ppo-{env_name}.zip\"\n",
    "        )\n",
    "        ppo_model = PPO.load(ppo_path, env=env, custom_objects=custom_objects)\n",
    "        models['ppo'] = ppo_model\n",
    "        print(\"PPO model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download PPO model: {e}\")\n",
    "        \n",
    "    try:\n",
    "        # DQN model\n",
    "        print(\"Downloading DQN model...\")\n",
    "        dqn_path = load_from_hub(\n",
    "            repo_id=f\"sb3/dqn-{env_name}\", \n",
    "            filename=f\"dqn-{env_name}.zip\"\n",
    "        )\n",
    "        dqn_model = DQN.load(dqn_path, env=env, custom_objects=custom_objects)\n",
    "        models['dqn'] = dqn_model\n",
    "        print(\"DQN model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download DQN model: {e}\")\n",
    "        \n",
    "    try:\n",
    "        # A2C model\n",
    "        print(\"Downloading A2C model...\")\n",
    "        a2c_path = load_from_hub(\n",
    "            repo_id=f\"sb3/a2c-{env_name}\",\n",
    "            filename=f\"a2c-{env_name}.zip\"\n",
    "        )\n",
    "        a2c_model = A2C.load(a2c_path, env=env, custom_objects=custom_objects)\n",
    "        models['a2c'] = a2c_model\n",
    "        print(\"A2C model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download A2C model: {e}\")\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27f5ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state_for_model(state_rgb, target_shape=(84, 84)):\n",
    "    \"\"\"\n",
    "    Preprocess RGB state to match model input requirements.\n",
    "    Atari models typically expect 84x84 grayscale or stacked frames.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(state_rgb.shape) == 3:\n",
    "        gray = cv2.cvtColor(state_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = state_rgb\n",
    "        \n",
    "    # Resize to target shape\n",
    "    resized = cv2.resize(gray, target_shape)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    normalized = resized.astype(np.float32) / 255.0\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def prepare_pixel_states(rgb_states, model_type='atari'):\n",
    "    \"\"\"\n",
    "    Prepare pixel states for model input.\n",
    "    \"\"\"\n",
    "    processed_states = []\n",
    "    \n",
    "    for state in rgb_states:\n",
    "        if model_type == 'atari':\n",
    "            # For Atari models, we need 4 stacked frames\n",
    "            processed = preprocess_state_for_model(state)\n",
    "            # Stack the same frame 4 times (approximation)\n",
    "            stacked = np.stack([processed] * 4, axis=0)\n",
    "            processed_states.append(stacked)\n",
    "        else:\n",
    "            processed_states.append(state)\n",
    "            \n",
    "    return np.array(processed_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee5c4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsa_matrix(activations):\n",
    "    \"\"\"\n",
    "    Compute RSA matrix from neural activations.\n",
    "    \"\"\"\n",
    "    # Flatten activations if they're multi-dimensional\n",
    "    if len(activations.shape) > 2:\n",
    "        activations_flat = activations.reshape(activations.shape[0], -1)\n",
    "    else:\n",
    "        activations_flat = activations\n",
    "        \n",
    "    # Compute pairwise correlations\n",
    "    rsa_matrix = np.corrcoef(activations_flat)\n",
    "    \n",
    "    return rsa_matrix\n",
    "\n",
    "def compare_matrices(behavioral_matrix, neural_matrix, method='pearson'):\n",
    "    \"\"\"\n",
    "    Compare behavioral similarity matrix with neural RSA matrix.\n",
    "    \"\"\"\n",
    "    # Get upper triangular indices (excluding diagonal)\n",
    "    n = behavioral_matrix.shape[0]\n",
    "    triu_indices = np.triu_indices(n, k=1)\n",
    "    \n",
    "    behavioral_flat = behavioral_matrix[triu_indices]\n",
    "    neural_flat = neural_matrix[triu_indices]\n",
    "    \n",
    "    if method == 'pearson':\n",
    "        corr, p_val = pearsonr(behavioral_flat, neural_flat)\n",
    "    elif method == 'spearman':\n",
    "        corr, p_val = spearmanr(behavioral_flat, neural_flat)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'pearson' or 'spearman'\")\n",
    "        \n",
    "    return corr, p_val\n",
    "\n",
    "def analyze_similarity_groups(behavioral_matrix, neural_matrix):\n",
    "    \"\"\"\n",
    "    Compare average neural similarity for behaviorally similar vs dissimilar states.\n",
    "    \"\"\"\n",
    "    # Get upper triangular indices\n",
    "    n = behavioral_matrix.shape[0]\n",
    "    triu_indices = np.triu_indices(n, k=1)\n",
    "    \n",
    "    behavioral_flat = behavioral_matrix[triu_indices]\n",
    "    neural_flat = neural_matrix[triu_indices]\n",
    "    \n",
    "    # Split into similar (1) and dissimilar (0) groups based on behavioral matrix\n",
    "    similar_mask = behavioral_flat == 1\n",
    "    dissimilar_mask = behavioral_flat == 0\n",
    "    \n",
    "    similar_neural = neural_flat[similar_mask]\n",
    "    dissimilar_neural = neural_flat[dissimilar_mask]\n",
    "    \n",
    "    results = {\n",
    "        'similar_mean': np.mean(similar_neural) if len(similar_neural) > 0 else np.nan,\n",
    "        'similar_std': np.std(similar_neural) if len(similar_neural) > 0 else np.nan,\n",
    "        'dissimilar_mean': np.mean(dissimilar_neural) if len(dissimilar_neural) > 0 else np.nan,\n",
    "        'dissimilar_std': np.std(dissimilar_neural) if len(dissimilar_neural) > 0 else np.nan,\n",
    "        'similar_count': len(similar_neural),\n",
    "        'dissimilar_count': len(dissimilar_neural)\n",
    "    }\n",
    "    \n",
    "    # Compute statistical test\n",
    "    if len(similar_neural) > 0 and len(dissimilar_neural) > 0:\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_val = ttest_ind(similar_neural, dissimilar_neural)\n",
    "        results['t_stat'] = t_stat\n",
    "        results['p_val'] = p_val\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33355ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading models from Hugging Face...\n",
      "Downloading PPO model...\n",
      "PPO model downloaded successfully\n",
      "Downloading DQN model...\n",
      "Failed to download DQN model: ReplayBuffer does not support optimize_memory_usage = True and handle_timeout_termination = True simultaneously.\n",
      "Downloading A2C model...\n",
      "A2C model downloaded successfully\n",
      "Downloaded 2 models: ['ppo', 'a2c']\n"
     ]
    }
   ],
   "source": [
    "# Download models\n",
    "print(\"Downloading models from Hugging Face...\")\n",
    "models = download_models()\n",
    "print(f\"Downloaded {len(models)} models: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "246fa138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pixel states...\n",
      "Collected 100 pixel states and 100 logical states\n"
     ]
    }
   ],
   "source": [
    "# First, let's collect some pixel states along with our logical states\n",
    "print(\"Collecting pixel states...\")\n",
    "\n",
    "# Initialize a fresh environment for pixel collection\n",
    "# pixel_env = gym.make(\n",
    "#     \"ALE/Pong-v5\",\n",
    "#     obs_type=\"rgb\",  # Get RGB pixels instead of RAM\n",
    "#     render_mode=None,\n",
    "# )\n",
    "\n",
    "pixel_env = gym.make(\"PongNoFrameskip-v4\")\n",
    "ale = pixel_env.unwrapped.ale\n",
    "\n",
    "# Collect states with both pixel and logical representations\n",
    "pixel_states = []\n",
    "ram_states = []\n",
    "logical_states = []\n",
    "\n",
    "num_episodes = 3\n",
    "max_steps = 500\n",
    "max_states_to_collect = 100\n",
    "\n",
    "for ep in range(num_episodes):\n",
    "    rgb_obs, _ = pixel_env.reset()\n",
    "    ram_obs = ale.getRAM()\n",
    "    \n",
    "    # Also get RAM version for logical state\n",
    "    # ram_env = gym.make(\"ALE/Pong-v5\", obs_type=\"ram\", render_mode=None)\n",
    "    # ram_obs, _ = ram_env.reset()\n",
    "    \n",
    "    prev_logical = None\n",
    "    \n",
    "    for t in range(max_steps):\n",
    "        if len(pixel_states) >= max_states_to_collect:\n",
    "            break\n",
    "            \n",
    "        # Store pixel state\n",
    "        pixel_states.append(rgb_obs)\n",
    "        \n",
    "        # Get corresponding logical state\n",
    "        ram_states.append(ram_obs)\n",
    "        logical_state = ram_to_logic_state(ram_obs, prev_state=prev_logical)\n",
    "        logical_states.append(logical_state)\n",
    "        prev_logical = logical_state\n",
    "        \n",
    "        # Take same action in both environments\n",
    "        action = pixel_env.action_space.sample()\n",
    "        \n",
    "        # rgb_obs, _, _, _, _ = pixel_env.step(action)\n",
    "        # aasdad = pixel_env.step(action)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        rgb_obs, reward, terminated, truncated, info = pixel_env.step(action)\n",
    "        ram_obs = ale.getRAM()\n",
    "        # ram_obs, _, _, _, _ = ram_env.step(action)\n",
    "        \n",
    "        if truncated or terminated:\n",
    "            break\n",
    "            \n",
    "    # ram_env.close()\n",
    "    \n",
    "    if len(pixel_states) >= max_states_to_collect:\n",
    "        break\n",
    "\n",
    "pixel_env.close()\n",
    "\n",
    "print(f\"Collected {len(pixel_states)} pixel states and {len(logical_states)} logical states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5393ad9-1cf9-4368-88c2-9dc42bb4a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env type: <class 'gym.wrappers.time_limit.TimeLimit'>\n",
      "unwrapped type: <class 'gym.envs.atari.environment.AtariEnv'>\n",
      "has ale? True\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "pixel_env = gym.make(\"PongNoFrameskip-v4\")\n",
    "print(\"env type:\", type(pixel_env))\n",
    "print(\"unwrapped type:\", type(pixel_env.unwrapped))\n",
    "print(\"has ale?\", hasattr(pixel_env.unwrapped, \"ale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb7f4cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing behavioral similarity matrix...\n",
      "Behavioral similarity matrix shape: (50, 50)\n",
      "Behavioral similarity stats:\n",
      "  total_states: 50\n",
      "  total_pairs: 1225\n",
      "  symmetric_pairs: 109\n",
      "  symmetry_ratio: 0.08897959183673469\n",
      "  diagonal_sum: 50\n"
     ]
    }
   ],
   "source": [
    "# Compute behavioral similarity matrix for our collected states\n",
    "print(\"Computing behavioral similarity matrix...\")\n",
    "\n",
    "# Use a subset of states for computational efficiency\n",
    "n_states = min(50, len(logical_states))\n",
    "subset_logical = logical_states[:n_states]\n",
    "subset_pixels = pixel_states[:n_states]\n",
    "\n",
    "# Create analyzer for the subset\n",
    "analyzer_subset = PongSymmetryAnalyzer()\n",
    "behavioral_matrix = analyzer_subset.generate_similarity_matrix(subset_logical)\n",
    "analyzer_subset.close()\n",
    "\n",
    "print(f\"Behavioral similarity matrix shape: {behavioral_matrix.shape}\")\n",
    "\n",
    "# Get statistics\n",
    "stats = analyzer_subset.get_similarity_stats(behavioral_matrix)\n",
    "print(\"Behavioral similarity stats:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b198ad5a-fcf2-45d1-b0f9-d4af26979cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ball_x': 192,\n",
       " 'ball_y': 192,\n",
       " 'ball_dx': 0,\n",
       " 'ball_dy': 0,\n",
       " 'player_y': 192,\n",
       " 'enemy_y': 192}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_states[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyzing PPO model ===\n",
      "Processed pixel states shape: (50, 4, 84, 84)\n",
      "> \u001b[32m/var/folders/w5/wtxn2_3x6jgbtxczqlsckq2r0000gp/T/ipykernel_89467/2842313008.py\u001b[39m(\u001b[92m15\u001b[39m)\u001b[36m<module>\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \n",
      "\u001b[32m     14\u001b[39m         \u001b[38;5;66;03m# Create activation extractor\u001b[39;00m\n",
      "\u001b[32m---> 15\u001b[39m         extractor = ModelActivationExtractor(model, model_name)\n",
      "\u001b[32m     16\u001b[39m         extractor.register_hooks()\n",
      "\u001b[32m     17\u001b[39m \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/var/folders/w5/wtxn2_3x6jgbtxczqlsckq2r0000gp/T/ipykernel_89467/2842313008.py\u001b[39m(\u001b[92m16\u001b[39m)\u001b[36m<module>\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     14\u001b[39m         \u001b[38;5;66;03m# Create activation extractor\u001b[39;00m\n",
      "\u001b[32m     15\u001b[39m         extractor = ModelActivationExtractor(model, model_name)\n",
      "\u001b[32m---> 16\u001b[39m         extractor.register_hooks()\n",
      "\u001b[32m     17\u001b[39m \n",
      "\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Extract activations\u001b[39;00m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'Linear' object is not iterable\n",
      "> \u001b[32m/var/folders/w5/wtxn2_3x6jgbtxczqlsckq2r0000gp/T/ipykernel_89467/2842313008.py\u001b[39m(\u001b[92m16\u001b[39m)\u001b[36m<module>\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     14\u001b[39m         \u001b[38;5;66;03m# Create activation extractor\u001b[39;00m\n",
      "\u001b[32m     15\u001b[39m         extractor = ModelActivationExtractor(model, model_name)\n",
      "\u001b[32m---> 16\u001b[39m         extractor.register_hooks()\n",
      "\u001b[32m     17\u001b[39m \n",
      "\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Extract activations\u001b[39;00m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform RSA analysis for each model\n",
    "rsa_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Analyzing {model_name.upper()} model ===\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare pixel states for the model\n",
    "        processed_pixels = prepare_pixel_states(subset_pixels, 'atari')\n",
    "        print(f\"Processed pixel states shape: {processed_pixels.shape}\")\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        \n",
    "        # Create activation extractor\n",
    "        extractor = ModelActivationExtractor(model, model_name)\n",
    "        extractor.register_hooks()\n",
    "        \n",
    "        # Extract activations\n",
    "        print(\"Extracting activations...\")\n",
    "        activations = extractor.extract_activations(processed_pixels)\n",
    "        \n",
    "        layer_results = {}\n",
    "        \n",
    "        for layer_name, layer_activations in activations.items():\n",
    "            print(f\"  Processing {layer_name} (shape: {layer_activations.shape})\")\n",
    "            \n",
    "            # Compute RSA matrix\n",
    "            rsa_matrix = compute_rsa_matrix(layer_activations)\n",
    "            \n",
    "            # Compare with behavioral matrix\n",
    "            corr_pearson, p_pearson = compare_matrices(behavioral_matrix, rsa_matrix, 'pearson')\n",
    "            corr_spearman, p_spearman = compare_matrices(behavioral_matrix, rsa_matrix, 'spearman')\n",
    "            \n",
    "            # Analyze similarity groups\n",
    "            group_analysis = analyze_similarity_groups(behavioral_matrix, rsa_matrix)\n",
    "            \n",
    "            layer_results[layer_name] = {\n",
    "                'rsa_matrix': rsa_matrix,\n",
    "                'pearson_corr': corr_pearson,\n",
    "                'pearson_p': p_pearson,\n",
    "                'spearman_corr': corr_spearman,\n",
    "                'spearman_p': p_spearman,\n",
    "                'group_analysis': group_analysis\n",
    "            }\n",
    "            \n",
    "            print(f\"    Pearson correlation: {corr_pearson:.4f} (p={p_pearson:.4f})\")\n",
    "            print(f\"    Spearman correlation: {corr_spearman:.4f} (p={p_spearman:.4f})\")\n",
    "            print(f\"    Similar group mean: {group_analysis['similar_mean']:.4f} ± {group_analysis['similar_std']:.4f}\")\n",
    "            print(f\"    Dissimilar group mean: {group_analysis['dissimilar_mean']:.4f} ± {group_analysis['dissimilar_std']:.4f}\")\n",
    "            if 'p_val' in group_analysis:\n",
    "                print(f\"    Group difference p-value: {group_analysis['p_val']:.4f}\")\n",
    "        \n",
    "        rsa_results[model_name] = layer_results\n",
    "        extractor.cleanup()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {model_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot behavioral similarity matrix\n",
    "im1 = axes[0].imshow(behavioral_matrix, cmap='viridis', vmin=0, vmax=1)\n",
    "axes[0].set_title('Behavioral Similarity Matrix')\n",
    "axes[0].set_xlabel('State Index')\n",
    "axes[0].set_ylabel('State Index')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot RSA matrices for different models/layers\n",
    "plot_idx = 1\n",
    "for model_name, model_results in rsa_results.items():\n",
    "    if plot_idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    # Get the first layer's RSA matrix for visualization\n",
    "    first_layer = list(model_results.keys())[0]\n",
    "    rsa_matrix = model_results[first_layer]['rsa_matrix']\n",
    "    \n",
    "    im = axes[plot_idx].imshow(rsa_matrix, cmap='viridis', vmin=-1, vmax=1)\n",
    "    axes[plot_idx].set_title(f'{model_name.upper()} - {first_layer}')\n",
    "    axes[plot_idx].set_xlabel('State Index')\n",
    "    axes[plot_idx].set_ylabel('State Index')\n",
    "    plt.colorbar(im, ax=axes[plot_idx])\n",
    "    plot_idx += 1\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(plot_idx, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0308526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table of correlations\n",
    "print(\"\\n=== RSA CORRELATION SUMMARY ===\")\n",
    "print(f\"{'Model':<10} {'Layer':<25} {'Pearson':<10} {'Spearman':<10} {'Sim Mean':<10} {'Dissim Mean':<12} {'P-value':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for model_name, model_results in rsa_results.items():\n",
    "    for layer_name, layer_results in model_results.items():\n",
    "        pearson = layer_results['pearson_corr']\n",
    "        spearman = layer_results['spearman_corr']\n",
    "        group_analysis = layer_results['group_analysis']\n",
    "        \n",
    "        sim_mean = group_analysis['similar_mean']\n",
    "        dissim_mean = group_analysis['dissimilar_mean']\n",
    "        p_val = group_analysis.get('p_val', np.nan)\n",
    "        \n",
    "        print(f\"{model_name:<10} {layer_name:<25} {pearson:<10.4f} {spearman:<10.4f} {sim_mean:<10.4f} {dissim_mean:<12.4f} {p_val:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparing similar vs dissimilar groups across models\n",
    "fig, axes = plt.subplots(1, len(rsa_results), figsize=(5*len(rsa_results), 6))\n",
    "if len(rsa_results) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (model_name, model_results) in enumerate(rsa_results.items()):\n",
    "    # Get first layer for visualization\n",
    "    first_layer = list(model_results.keys())[0]\n",
    "    group_analysis = model_results[first_layer]['group_analysis']\n",
    "    \n",
    "    means = [group_analysis['similar_mean'], group_analysis['dissimilar_mean']]\n",
    "    stds = [group_analysis['similar_std'], group_analysis['dissimilar_std']]\n",
    "    labels = ['Behaviorally\\nSimilar', 'Behaviorally\\nDissimilar']\n",
    "    \n",
    "    bars = axes[idx].bar(labels, means, yerr=stds, capsize=5, \n",
    "                        color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "    axes[idx].set_title(f'{model_name.upper()}\\n{first_layer}')\n",
    "    axes[idx].set_ylabel('Neural Similarity')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add significance test result\n",
    "    if 'p_val' in group_analysis:\n",
    "        p_val = group_analysis['p_val']\n",
    "        if p_val < 0.001:\n",
    "            sig_text = '***'\n",
    "        elif p_val < 0.01:\n",
    "            sig_text = '**'\n",
    "        elif p_val < 0.05:\n",
    "            sig_text = '*'\n",
    "        else:\n",
    "            sig_text = 'n.s.'\n",
    "        \n",
    "        # Add significance annotation\n",
    "        y_max = max(means) + max(stds)\n",
    "        axes[idx].text(0.5, y_max * 1.1, sig_text, ha='center', va='bottom', fontsize=14)\n",
    "        axes[idx].text(0.5, y_max * 1.15, f'p={p_val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sac",
   "language": "python",
   "name": "sac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
